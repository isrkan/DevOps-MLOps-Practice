{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5fc5ee4-541b-4993-865f-18934484856b",
   "metadata": {},
   "source": [
    "# Autologging in MLflow\n",
    "\n",
    "MLflow's autologging automatically logs parameters, metrics, models, and artifacts for supported machine learning libraries. This makes tracking experiments easier and more efficient, without the need to manually log each item.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Load and preprocess the California housing dataset.\n",
    "- Train different types of models using multiple machine learning libraries.\n",
    "- Use MLflow's autologging feature to track the experiments for each model. MLflow provides built-in support for automatically logging experiments of machine learning models from different libraries.\n",
    "- All models will be logged under a single MLflow experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f7ed91-dba5-4243-8d11-e68ad0195e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.statsmodels\n",
    "import mlflow.keras\n",
    "import mlflow.pytorch\n",
    "import mlflow.xgboost\n",
    "import mlflow.catboost\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger('mlflow').setLevel(logging.ERROR)\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f613d1-f68d-402c-a8a9-b468febafc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X = housing.data\n",
    "y = housing.target\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f598b-97d7-49e9-af93-90f0e5e78d57",
   "metadata": {},
   "source": [
    "### Setting up the experiment\n",
    "\n",
    "We will start by setting up a new MLflow experiment where all runs will be logged. If the experiment does not exist, it will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df727fcc-f088-4d3c-a7ce-e1ec369774ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/israe/Documents/Codes/Notebooks/mlruns/328990853911858228', creation_time=1724614767818, experiment_id='328990853911858228', last_update_time=1724614767818, lifecycle_stage='active', name='California Housing Regression Autologging', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the experiment\n",
    "mlflow.set_experiment(\"California Housing Regression Autologging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b5306-69d3-4367-a2a3-7876561e7f84",
   "metadata": {},
   "source": [
    "### Autologging `statsmodels` models\n",
    "\n",
    "First, we will demonstrate how to autolog models using the MLflow's `statsmodels` autologging. We will train three different regression models using `statsmodels` and log them with autologging. To use autologging with `statsmodels`, we simply need to call `mlflow.statsmodels.autolog()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02bbb993-08fc-46a2-b59e-09d7d330fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for statsmodels\n",
    "mlflow.statsmodels.autolog()\n",
    "\n",
    "# Define and train models with autologging\n",
    "for model_type in ['OLS', 'WLS', 'GLS']:\n",
    "    mlflow.start_run(run_name=f\"Statsmodels-{model_type}\")\n",
    "\n",
    "    if model_type == 'OLS':\n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "    elif model_type == 'WLS':\n",
    "        model = sm.WLS(y_train, X_train).fit()\n",
    "    elif model_type == 'GLS':\n",
    "        model = sm.GLS(y_train, X_train).fit()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0564b22-23c3-403c-a940-ca53856ac68b",
   "metadata": {},
   "source": [
    "**Logged features**\n",
    "\n",
    "When autologging is enabled for `statsmodels`, MLflow automatically logs the following information:\n",
    "\n",
    "- **Model parameters**: Logs the parameters passed during model instantiation. If defaults are used, these are also recorded.\n",
    "- **Model evaluation metrics**: Automatically logs metrics like MSE and R-squared. To log other metrics, we need to calculate them manually using `mlflow.log_metric()`.\n",
    "- **Artifacts**:\n",
    "  - **Model file**: The trained model is logged as an artifact. By default, the model is serialized using the `statsmodels` format.\n",
    "  - **Model summary**: The model's summary is saved as a `.txt` file artifact, which includes key statistics like coefficients, R-squared values, p-values, etc.\n",
    "- **Tags**: While MLflow adds basic tags like `mlflow.source.type` and `mlflow.source.name`, MLflow does not set additional default tags for `statsmodels`. We can manually add more tags to further categorize or describe the run.\n",
    "- **Datasets**: The actual datasets (`X_train`, `y_train`) and their shapes are not logged by default. To log them, we would need to do that manually using `mlflow.log_artifact()` or by saving the dataset to a file and then logging it.\n",
    "\n",
    "\n",
    "### Autologging `sklearn` models\n",
    "\n",
    "Next, we'll train three different regression models using Scikit-learn and log them with MLflow's `sklearn` autologging. To use autologging with Scikit-learn, we simply call `mlflow.sklearn.autolog()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672a656d-a998-4a24-9452-e6f03e136344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for scikit-learn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso()\n",
    "}\n",
    "\n",
    "# Train models with autologging\n",
    "for model_name, model in models.items():\n",
    "    mlflow.start_run(run_name=f\"Sklearn-{model_name}\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef164bab-f47b-459b-8fdd-40bdcc57bfd8",
   "metadata": {},
   "source": [
    "**Logged features**\n",
    "\n",
    "When autologging is enabled for `scikit-learn` models, MLflow automatically logs the following:\n",
    "\n",
    "- **Model parameters**: Logs the hyperparameters used for the models, such as `alpha` for Ridge and Lasso. If default values are used, these are also recorded.\n",
    "- **Model evaluation metrics**: Automatically logs common regression metrics like MSE and MAE for traning and validation sets. Additional metrics can be manually logged using `mlflow.log_metric()`.\n",
    "- **Artifacts**:\n",
    "  - **Model file**: The trained model is logged as an artifact. By default, itâ€™s serialized using the `pickle` format.\n",
    "- **Tags**: MLflow adds some default tags, such as `mlflow.source.type` and `mlflow.source.name`. It also  set additional default tags for `sklearn` such as `estimator_class` and `estimator_name`. Custom tags can be added manually to further describe or categorize the run.\n",
    "- **Datasets**: The datasets (`X_train`, `y_train`) are not logged automatically, but it logs their metadata such as input shapes and size. If we need to log the datasets, we can do so manually using `mlflow.log_artifact()`.\n",
    "\n",
    "### Autologging `keras` models\n",
    "In this section, we will train three regression models using Keras and log them with MLflow's `keras` autologging. To use autologging with Keras, we simply call `mlflow.keras.autolog()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d83d5f10-b6f3-44c7-b06a-93db0232aad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    }
   ],
   "source": [
    "# Enable autologging for Keras\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "# Define a function to create a Keras model\n",
    "def create_keras_model(units=64, activation='relu'):\n",
    "    model = Sequential([\n",
    "        Dense(units, activation=activation, input_shape=(X_train.shape[1],)),\n",
    "        Dense(units, activation=activation),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Train models with different configurations\n",
    "for units in [32, 64, 128]:\n",
    "    mlflow.start_run(run_name=f\"Keras-{units}units\")\n",
    "    \n",
    "    model = create_keras_model(units=units)\n",
    "    model.fit(X_train, y_train, epochs=10, validation_split=0.2, verbose=0)\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c98f10-c52f-4ec0-8b35-c080d435e1f4",
   "metadata": {},
   "source": [
    "**Logged features**\n",
    "\n",
    "When autologging is enabled for `keras` models, MLflow automatically logs the following:\n",
    "\n",
    "- **Model parameters**: Logs the parameters used during model creation, such as the epochs and batch size.\n",
    "- **Model evaluation metrics**: Automatically logs training and validation metrics that we defined in `model.compile` such as the loss and other defined metrics. It logs these matrices for each epoch.\n",
    "- **Artifacts**:\n",
    "  - **Model file**: The trained model is logged as an artifact. The default format in which Keras models are saved when using TensorFlow 2.x (and MLflow's autologging) is the SavedModel format (`saved_model.pb`). This is the most comprehensive format, capturing all the details necessary for restoring the model completely and deploying it in production. If we explicitly save our model using `model.save('model.h5')`, then it will be saved in the HDF5 format. However, newer versions of Keras may recommend saving models in the `.keras` format instead.\n",
    "  - **Model summary**: The model's summary is saved as a `.txt` file artifact, which includes an overview of the model architecture.\n",
    "  - **TensorBoard logs**: If TensorBoard is used during training, the logs are automatically captured and stored as artifacts. These logs contain detailed information about the training process, such as loss and metric curves, histograms of weights and biases, and other debugging data.\n",
    "  \n",
    "- **Tags**: While MLflow adds basic tags like `mlflow.source.type` and `mlflow.source.name`, MLflow does not set additional default tags for `keras`. We can manually add more tags to further categorize or describe the run.\n",
    "- **Datasets**: The datasets themselves (`X_train`, `y_train`) are not logged automatically, but metadata such as input shapes and sizes are captured. If we need to log the datasets, we can manually do so using `mlflow.log_artifact()`.\n",
    "\n",
    "\n",
    "### Autologging `pytorch` models\n",
    "MLflow's autologging for PyTorch is designed to work with **PyTorch Lightning**, a high-level library that abstracts away much of the boilerplate code involved in training PyTorch models. This means that if we are using plain PyTorch, MLflow's `mlflow.pytorch.autolog()` won't capture the logs automatically. Instead, autologging is triggered when using PyTorch Lightning's `Trainer` class.\n",
    "\n",
    "For plain PyTorch, we need to manually log model parameters, evaluation metrics, and other artifacts using `mlflow.log_metric()`, `mlflow.log_params()`, and `mlflow.log_artifact()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dae3b55-1ceb-4863-b24b-c9aa01da51be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | fc1       | Linear  | 288    | train\n",
      "1 | fc2       | Linear  | 1.1 K  | train\n",
      "2 | fc3       | Linear  | 33     | train\n",
      "3 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e10025f4673454b925e6b8e5bcd013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | fc1       | Linear  | 576    | train\n",
      "1 | fc2       | Linear  | 4.2 K  | train\n",
      "2 | fc3       | Linear  | 65     | train\n",
      "3 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "4.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40327c864b6d4e4eaf23f1e490e16db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.callbacks.model_summary:\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | fc1       | Linear  | 1.2 K  | train\n",
      "1 | fc2       | Linear  | 16.5 K | train\n",
      "2 | fc3       | Linear  | 129    | train\n",
      "3 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "17.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.8 K    Total params\n",
      "0.071     Total estimated model params size (MB)\n",
      "4         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3fd41d1d594f6b928f330e25464620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                      | 0/? [00:00<â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# Define PyTorch Lightning model\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(LitModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch, y_batch = batch\n",
    "        y_pred = self(X_batch).squeeze()\n",
    "        loss = self.criterion(y_pred, y_batch)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n",
    "\n",
    "# Enable autologging for PyTorch Lightning\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Prepare data\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32))\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Train models with different hidden layer sizes\n",
    "for hidden_dim in [32, 64, 128]:\n",
    "    mlflow.start_run(run_name=f\"Pytorch-{hidden_dim}hidden\")\n",
    "    model = LitModel(input_dim=X_train.shape[1], hidden_dim=hidden_dim)\n",
    "    \n",
    "    trainer = pl.Trainer(max_epochs=10)\n",
    "    trainer.fit(model, train_loader)\n",
    "\n",
    "    # Predict on the test set\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    with torch.no_grad():  # Turn off gradient computation\n",
    "        for X_batch, _ in test_loader:\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "\n",
    "    mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc7261-30ca-485c-bcf1-ff099ff0ba4b",
   "metadata": {},
   "source": [
    "**Logged features**\n",
    "\n",
    "When using MLflow's autologging with PyTorch Lightning, the following features are automatically logged:\n",
    "\n",
    "- **Model parameters**: Logs hyperparameters used for training the model, such as `lr`, `epochs`, etc.\n",
    "- **Model evaluation metrics**: `mlflow.pytorch.autolog()` does not automatically log evaluation metrics based on the training and test data unless they are specified or calculated manually. To log metrics automatically, ensure they are calculated within the training process or manually log them after predictions.\n",
    "- **Artifacts**:\n",
    "  - **Model file**: The trained PyTorch model is saved using PyTorch's native format (`.pt` or `.pth`).\n",
    "  - **Model summary**: The model's summary is saved as a `.txt` file artifact, which includes an overview of the model architecture.\n",
    "- **Tags**: MLflow automatically logs basic tags and additional tags related to PyTorch Lightning such as `Mode`.\n",
    "- **Datasets**: The actual datasets (`X_train`, `y_train`) and their shapes are not logged by default. To log them, we would need to do that manually using `mlflow.log_artifact()` or by saving the dataset to a file and then logging it.\n",
    "\n",
    "\n",
    "### Autologging `XGBoost` model\n",
    "\n",
    "In this section, we will train a regression model using XGBoost and log the process using `mlflow.xgboost`. Autologging for XGBoost is enabled by calling `mlflow.xgboost.autolog()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a964ebce-7089-4116-bc0a-2f1090569b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for XGBoost\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# Train XGBoost model\n",
    "mlflow.start_run(run_name=\"XGBoost\")\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337d8ea3-0e92-4c0e-85e7-3b9e1c1c9359",
   "metadata": {},
   "source": [
    "**Logged features**\n",
    "\n",
    "MLflow automatically logs several important features related to the model and the training process. Here's what gets logged:\n",
    "\n",
    "- **Model parameters**: Logs all the hyperparameters used for the XGBoost model, such as `learning_rate`, `n_jobs`, `max_depth`, etc.\n",
    "- **Model evaluation metrics**: If we evaluate the model's performance (e.g., calculating metrics like RMSE, MAE, etc.) after training, these metrics can be manually logged using `mlflow.log_metric()`. However, `mlflow.xgboost.autolog()` does not automatically log evaluation metrics based on the training and test data unless they are specified or calculated manually. To log metrics automatically, ensure they are calculated within the training process or manually log them after predictions.\n",
    "- **Artifacts**:\n",
    "  - **Model file**: The model is saved in the XGBoost-specific binary format (`.xgb`), which includes the entire model (structure and trained parameters). This format is specific to XGBoost and is optimized for quick loading and efficient storage. \n",
    "  - **Feature importance**: A plot and text files showing the importance of each feature used in the model.\n",
    "- **Tags**: MLflow adds standard tags like `mlflow.source.type` and `mlflow.source.name`. Additional tags specific to XGBoost, can be logged manually if needed.\n",
    "- **Datasets**: Similar to other models, the datasets themselves are not logged automatically, but metadata such as input shapes and sizes are captured. We would need to log the datasets manually if required using `mlflow.log_artifact()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a316e6-2eba-4138-a00d-13fdebd0b153",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "Autologging is a powerful feature that simplifies tracking experiments, but manual logging provides more control over what and how data is recorded, especially for custom needs or unsupported scenarios.\n",
    "\n",
    "- **Use autologging when**: \n",
    "  - We need automatic and comprehensive logging of model training, parameters, and metrics.\n",
    "  - Working with supported libraries (e.g., `statsmodels`, `scikit-learn`, `keras` with TensorFlow, `xgboost`, PyTorch Lightning).\n",
    "\n",
    "- **Log manually when**:\n",
    "  - We need to log custom metrics, datasets, or specific model details not covered by autologging.\n",
    "  - Using libraries or frameworks not fully supported by MLflow's autologging (e.g., standard PyTorch)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
